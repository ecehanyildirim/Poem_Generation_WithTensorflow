{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "poem_generation.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ecehanyildirim/Poem_Generation_WithTensorflow/blob/main/poem_generation_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t09eeeR5prIJ"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGyKZj3bzf9p"
      },
      "source": [
        "### Import TensorFlow and other libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG_n40gFzf9s"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXI2evKr79-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1957661a-9608-4a91-cbcc-e8f81d691d94"
      },
      "source": [
        "text = open(\"siir.txt\",'rb').read().decode(encoding='utf-8')\n",
        "#text = open(\"kahramanlık.txt\",'rb').read().decode(encoding='utf-8')\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 686540 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHjdCjDuSvX_"
      },
      "source": [
        "### Read the data\n",
        "\n",
        "First, look in the text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duhg9NrUymwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef6aafd-2947-4f54-95e1-1072b50301d8"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "YAD*\r\n",
            "Güzel günlerim vardı yağmurlarla ıslanan,\r\n",
            "Ve güzel gecelerim masallarla dopdolu.\r\n",
            "Her şey, her şey güzeldi, gözyaşı, dünya, zaman,\r\n",
            "Böğürtlen topladığım ıssız, tozlu köy yolu,\r\n",
            "Güzel günlerim vardı yağmurlarla ıslanan.\r\n",
            "Ufacık korumuzda dola\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlCgQBRVymwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197f93a3-6c70-45e0-bd56-344c25f2be4e"
      },
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "109 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNnrKn_lL-IJ"
      },
      "source": [
        "## Process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFjSVAlWzf-N"
      },
      "source": [
        "### Vectorize the text\n",
        "\n",
        "Before training, you need to convert the strings to a numerical representation. \n",
        "\n",
        "The `preprocessing.StringLookup` layer can convert each character into a numeric ID. It just needs the text to be split into tokens first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a86OoYtO01go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d725afbd-9c76-445c-f6ac-77ec6fea4e3d"
      },
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s4f1q3iqY8f"
      },
      "source": [
        "Now create the `preprocessing.StringLookup` layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GMlCe3qzaL9"
      },
      "source": [
        "ids_from_chars = preprocessing.StringLookup(\n",
        "    vocabulary=list(vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmX_jbgQqfOi"
      },
      "source": [
        "It converts form tokens to character IDs, padding with `0`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLv5Q_2TC2pc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516dcbd2-59c0-425f-89bb-25d39916fb50"
      },
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[59, 60, 61, 62, 63, 64, 65], [82, 83, 84]]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZfqhkYCymwX"
      },
      "source": [
        "Since the goal of this tutorial is to generate text, it will also be important to invert this representation and recover human-readable strings from it. For this you can use `preprocessing.StringLookup(..., invert=True)`.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uenivzwqsDhp"
      },
      "source": [
        "Note: Here instead of passing the original vocabulary generated with `sorted(set(text))` use the `get_vocabulary()` method of the `preprocessing.StringLookup` layer so that the padding and `[UNK]` tokens are set the same way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2m3mqkDjRj"
      },
      "source": [
        "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqTDDxS-s-H8"
      },
      "source": [
        "This layer recovers the characters from the vectors of IDs, and returns them as a `tf.RaggedTensor` of characters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2GCh0ySD44s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51e330f3-592b-4a96-cb1a-eacb302795a1"
      },
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FeW5gqutT3o"
      },
      "source": [
        "You can `tf.strings.reduce_join` to join the characters back into strings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxYI-PeltqKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b646009-5d70-443b-ec4b-1e390a5c49f9"
      },
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5apvBDn9Ind"
      },
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmsf23Bymwe"
      },
      "source": [
        "### The prediction task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wssHQ1oGymwe"
      },
      "source": [
        "Given a character, or a sequence of characters, what is the most probable next character? This is the task you're training the model to perform. The input to the model will be a sequence of characters, and you train the model to predict the output—the following character at each time step.\n",
        "\n",
        "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsVvVxnymwf"
      },
      "source": [
        "### Create training examples and targets\n",
        "\n",
        "Next divide the text into example sequences. Each input sequence will contain `seq_length` characters from the text.\n",
        "\n",
        "For each input sequence, the corresponding targets contain the same length of text, except shifted one character to the right.\n",
        "\n",
        "So break the text into chunks of `seq_length+1`. For example, say `seq_length` is 4 and our text is \"Hello\". The input sequence would be \"Hell\", and the target sequence \"ello\".\n",
        "\n",
        "To do this first use the `tf.data.Dataset.from_tensor_slices` function to convert the text vector into a stream of character indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UopbsKi88tm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b006acb-aa55-451d-fb62-5e8075a941ca"
      },
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(686540,), dtype=int64, numpy=array([ 3,  2, 53, ...,  2,  3,  2])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmxrYDCTy-eL"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjH5v45-yqqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24c6e95a-f4c5-485a-fe59-6fc85bf0576b"
      },
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "\n",
            "\n",
            "Y\n",
            "A\n",
            "D\n",
            "*\n",
            "\r\n",
            "\n",
            "\n",
            "G\n",
            "ü\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-G2oaTxy6km"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZSYAcQV8OGP"
      },
      "source": [
        "The `batch` method lets you easily convert these individual characters to sequences of the desired size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpdjRO2CzOfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7210e8ae-c3df-45bf-ce91-6aa47c6b622f"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'\\r' b'\\n' b'Y' b'A' b'D' b'*' b'\\r' b'\\n' b'G' b'\\xc3\\xbc' b'z' b'e'\n",
            " b'l' b' ' b'g' b'\\xc3\\xbc' b'n' b'l' b'e' b'r' b'i' b'm' b' ' b'v' b'a'\n",
            " b'r' b'd' b'\\xc4\\xb1' b' ' b'y' b'a' b'\\xc4\\x9f' b'm' b'u' b'r' b'l' b'a'\n",
            " b'r' b'l' b'a' b' ' b'\\xc4\\xb1' b's' b'l' b'a' b'n' b'a' b'n' b',' b'\\r'\n",
            " b'\\n' b'V' b'e' b' ' b'g' b'\\xc3\\xbc' b'z' b'e' b'l' b' ' b'g' b'e' b'c'\n",
            " b'e' b'l' b'e' b'r' b'i' b'm' b' ' b'm' b'a' b's' b'a' b'l' b'l' b'a'\n",
            " b'r' b'l' b'a' b' ' b'd' b'o' b'p' b'd' b'o' b'l' b'u' b'.' b'\\r' b'\\n'\n",
            " b'H' b'e' b'r' b' ' b'\\xc5\\x9f' b'e' b'y' b',' b' ' b'h'], shape=(101,), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PHW902-4oZt"
      },
      "source": [
        "It's easier to see what this is doing if you join the tokens back into strings:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO32cMWu4a06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c5d028-ad58-4afe-99cd-e8296b183624"
      },
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'\\r\\nYAD*\\r\\nG\\xc3\\xbczel g\\xc3\\xbcnlerim vard\\xc4\\xb1 ya\\xc4\\x9fmurlarla \\xc4\\xb1slanan,\\r\\nVe g\\xc3\\xbczel gecelerim masallarla dopdolu.\\r\\nHer \\xc5\\x9fey, h'\n",
            "b'er \\xc5\\x9fey g\\xc3\\xbczeldi, g\\xc3\\xb6zya\\xc5\\x9f\\xc4\\xb1, d\\xc3\\xbcnya, zaman,\\r\\nB\\xc3\\xb6\\xc4\\x9f\\xc3\\xbcrtlen toplad\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1m \\xc4\\xb1ss\\xc4\\xb1z, tozlu k\\xc3\\xb6y yolu,\\r\\nG\\xc3\\xbczel g\\xc3\\xbcnlerim v'\n",
            "b'ard\\xc4\\xb1 ya\\xc4\\x9fmurlarla \\xc4\\xb1slanan.\\r\\nUfac\\xc4\\xb1k korumuzda dola\\xc5\\x9f\\xc4\\xb1rd\\xc4\\xb1m korkuyla,\\r\\nVe Allah\\xc4\\xb1 arard\\xc4\\xb1m ser\\xc3\\xa7e yuvalar\\xc4\\xb1nda'\n",
            "b',\\r\\nBulamay\\xc4\\xb1nca dua yollard\\xc4\\xb1m akan suyla,\\r\\nG\\xc3\\xb6\\xc4\\x9f\\xc3\\xbc bulutlar saran bahar havalar\\xc4\\xb1nda,\\r\\nDola\\xc5\\x9f\\xc4\\xb1rd\\xc4\\xb1m ufac\\xc4\\xb1k k'\n",
            "b'orumuzda korkuyla.\\r\\nSeyrederdim g\\xc3\\xb6klerde her g\\xc3\\xbcn b\\xc3\\xbcy\\xc3\\xbcyen ay\\xc4\\xb1.\\r\\nVe kale duvar\\xc4\\xb1ndan y\\xc4\\xb1k\\xc4\\xb1k mezarl\\xc4\\xb1klar\\xc4\\xb1,'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbLcIPBj_mWZ"
      },
      "source": [
        "For training you'll need a dataset of `(input, label)` pairs. Where `input` and \n",
        "`label` are sequences. At each time step the input is the current character and the label is the next character. \n",
        "\n",
        "Here's a function that takes a sequence as input, duplicates, and shifts it to align the input and label for each timestep:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NGu-FkO_kYU"
      },
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbDTJTw5u_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf277fe1-b98f-4c03-bd24-1025ec9bfdf1"
      },
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9iKPXkw5xwa"
      },
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNbw-iR0ymwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a8898ed-dafd-45af-f9d1-f36a22c23e6f"
      },
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input : b'\\r\\nYAD*\\r\\nG\\xc3\\xbczel g\\xc3\\xbcnlerim vard\\xc4\\xb1 ya\\xc4\\x9fmurlarla \\xc4\\xb1slanan,\\r\\nVe g\\xc3\\xbczel gecelerim masallarla dopdolu.\\r\\nHer \\xc5\\x9fey, '\n",
            "Target: b'\\nYAD*\\r\\nG\\xc3\\xbczel g\\xc3\\xbcnlerim vard\\xc4\\xb1 ya\\xc4\\x9fmurlarla \\xc4\\xb1slanan,\\r\\nVe g\\xc3\\xbczel gecelerim masallarla dopdolu.\\r\\nHer \\xc5\\x9fey, h'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJdfPmdqzf-R"
      },
      "source": [
        "### Create training batches\n",
        "\n",
        "You used `tf.data` to split the text into manageable sequences. But before feeding this data into the model, you need to shuffle the data and pack it into batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2pGotuNzf-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07024795-c2ef-44e9-ad18-b438c8957250"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6oUuElIMgVx"
      },
      "source": [
        "## Build The Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8gPwEjRzf-Z"
      },
      "source": [
        "This section defines the model as a `keras.Model` subclass (For details see [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)). \n",
        "\n",
        "This model has three layers:\n",
        "\n",
        "* `tf.keras.layers.Embedding`: The input layer. A trainable lookup table that will map each character-ID to a vector with `embedding_dim` dimensions;\n",
        "* `tf.keras.layers.GRU`: A type of RNN with size `units=rnn_units` (You can also use an LSTM layer here.)\n",
        "* `tf.keras.layers.Dense`: The output layer, with `vocab_size` outputs. It outputs one logit for each character in the vocabulary. These are the log-likelihood of each character according to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHT8cLh7EAsg"
      },
      "source": [
        "# Length of the vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj8HQ2w8z4iO"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX58Xj9z47Aw"
      },
      "source": [
        "model = MyModel(\n",
        "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkA5upJIJ7W7"
      },
      "source": [
        "For each character the model looks up the embedding, runs the GRU one timestep with the embedding as input, and applies the dense layer to generate logits predicting the log-likelihood of the next character:\n",
        "\n",
        "![A drawing of the data passing through the model](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/text_generation_training.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKbfm04amhXk"
      },
      "source": [
        "Note: For training you could use a `keras.Sequential` model here. To  generate text later you'll need to manage the RNN's internal state. It's simpler to include the state input and output options upfront, than it is to rearrange the model architecture later. For more details see the [Keras RNN guide](https://www.tensorflow.org/guide/keras/rnn#rnn_state_reuse)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ubPo0_9Prjb"
      },
      "source": [
        "## Try the model\n",
        "\n",
        "Now run the model to see that it behaves as expected.\n",
        "\n",
        "First check the shape of the output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-_70kKAPrPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd64bad8-e748-4bb4-f2b0-63161f736be1"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 100, 111) # (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6NzLBi4VM4o"
      },
      "source": [
        "In the above example the sequence length of the input is `100` but the model can be run on inputs of any length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPGmAAXmVLGC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00babd4-6c35-4dff-cdf3-cf326958af22"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  28416     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  113775    \n",
            "=================================================================\n",
            "Total params: 4,080,495\n",
            "Trainable params: 4,080,495\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwv0gEkURfx1"
      },
      "source": [
        "To get actual predictions from the model you need to sample from the output distribution, to get actual character indices. This distribution is defined by the logits over the character vocabulary.\n",
        "\n",
        "Note: It is important to _sample_ from this distribution as taking the _argmax_ of the distribution can easily get the model stuck in a loop.\n",
        "\n",
        "Try it for the first example in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V4MfFg0RQJg"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM1Vbxs_URw5"
      },
      "source": [
        "This gives us, at each timestep, a prediction of the next character index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqFMUQc_UFgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0f6704-16a4-4e56-c4aa-720404431682"
      },
      "source": [
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 56,   5, 102,  11,  26,  59,  18,  20,  47,  63,  60,   8,  81,\n",
              "        46,  72, 108,  44,  46,  24,  28,   4,  89,   6,  20,  20,  17,\n",
              "        38,  98,   6,  38,  83,  95,  56,  13,  43,  38, 103,  73,  25,\n",
              "        99,  75,   7,  26,  24,  67,  86, 102,  66,  71,  70,  93,  83,\n",
              "        78,  23,  25,   7,  13,  25,  63,  62,  95,  58,  90,   9,  33,\n",
              "        70,  75,  58,  58,  55,  27,  73,  93, 105,  38,  88,  46,  61,\n",
              "       108,  48,  66,  37,  54,  60, 110,  75,  90,   1,  10,  50,  66,\n",
              "        52,  84,  30,  11,  67,   5, 100,  31,  99])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfLtsP3mUhCG"
      },
      "source": [
        "Decode these to see the text predicted by this untrained model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWcFwPwLSo05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6fcbf4-6c0e-4919-838a-d0198f87c7b0"
      },
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'O g\\xc3\\xbcn, bir evde, o kedi\\r\\nBeni taa \\xc3\\xa7ocuklu\\xc4\\x9fumdan ald\\xc4\\xb1\\r\\nO g\\xc3\\xbcn, o evdeki, o kedi,\\r\\nBak-i\\xc5\\x9fte, neler olmu'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'\\\\!\\xc5\\x9f,;a35Seb(wRn\\xe2\\x80\\xa2OR9> \\xc3\\x96\"552I\\xc4\\x9f\"Iy\\xc3\\xbb\\\\.NI\\xe2\\x80\\x93o:\\xc4\\xb0q\\';9i\\xc2\\xbb\\xc5\\x9fhml\\xc3\\xaeyt8:\\'.:ed\\xc3\\xbb^\\xc3\\x9c)Dlq^^[<o\\xc3\\xae\\xe2\\x80\\x99I\\xc3\\x87Rc\\xe2\\x80\\xa2ThHZb\\xe2\\x96\\xa0q\\xc3\\x9c[UNK]*VhXzA,i!\\xc4\\xb1B\\xc4\\xb0'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJL0Q0YPY6Ee"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCbHQHiaa4Ic"
      },
      "source": [
        "At this point the problem can be treated as a standard classification problem. Given the previous RNN state, and the input this time step, predict the class of the next character."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpqTWyvk0nr"
      },
      "source": [
        "### Attach an optimizer, and a loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAjbjY03eiQ4"
      },
      "source": [
        "The standard `tf.keras.losses.sparse_categorical_crossentropy` loss function works in this case because it is applied across the last dimension of the predictions.\n",
        "\n",
        "Because your model returns logits, you need to set the `from_logits` flag.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOeWdgxNFDXq"
      },
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HrXTACTdzY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93b15a3-f122-49e9-a201-e0b9669ff68a"
      },
      "source": [
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "mean_loss = example_batch_loss.numpy().mean()\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", mean_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 111)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         4.7098055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkvUIneTFiow"
      },
      "source": [
        "A newly initialized model shouldn't be too sure of itself, the output logits should all have similar magnitudes. To confirm this you can check that the exponential of the mean loss is approximately equal to the vocabulary size. A much higher loss means the model is sure of its wrong answers, and is badly initialized:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAJfS5YoFiHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c0b8d1-ba59-4b9c-b979-4c92c60559de"
      },
      "source": [
        "tf.exp(mean_loss).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "111.03056"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeOXriLcymww"
      },
      "source": [
        "Configure the training procedure using the `tf.keras.Model.compile` method. Use `tf.keras.optimizers.Adam` with default arguments and the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDl1_Een6rL0"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieSJdchZggUj"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6XBUUavgF56"
      },
      "source": [
        "Use a `tf.keras.callbacks.ModelCheckpoint` to ensure that checkpoints are saved during training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6fWTriUZP-n"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ky3F_BhgkTW"
      },
      "source": [
        "### Execute the training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxdOA-rgyGvs"
      },
      "source": [
        "To keep training time reasonable, use 10 epochs to train the model. In Colab, set the runtime to GPU for faster training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBE2zxMMHs"
      },
      "source": [
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK-hmKjYVoll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff038d13-6185-4457-9b60-7ff5778cea6e"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "106/106 [==============================] - 8s 52ms/step - loss: 2.9373\n",
            "Epoch 2/20\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 2.1758\n",
            "Epoch 3/20\n",
            "106/106 [==============================] - 6s 52ms/step - loss: 2.0254\n",
            "Epoch 4/20\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 1.9058\n",
            "Epoch 5/20\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 1.7964\n",
            "Epoch 6/20\n",
            "106/106 [==============================] - 6s 53ms/step - loss: 1.7021\n",
            "Epoch 7/20\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 1.6196\n",
            "Epoch 8/20\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 1.5485\n",
            "Epoch 9/20\n",
            "106/106 [==============================] - 6s 54ms/step - loss: 1.4811\n",
            "Epoch 10/20\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 1.4160\n",
            "Epoch 11/20\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 1.3507\n",
            "Epoch 12/20\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 1.2830\n",
            "Epoch 13/20\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 1.2122\n",
            "Epoch 14/20\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 1.1382\n",
            "Epoch 15/20\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 1.0602\n",
            "Epoch 16/20\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 0.9803\n",
            "Epoch 17/20\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.8971\n",
            "Epoch 18/20\n",
            "106/106 [==============================] - 6s 56ms/step - loss: 0.8115\n",
            "Epoch 19/20\n",
            "106/106 [==============================] - 7s 56ms/step - loss: 0.7291\n",
            "Epoch 20/20\n",
            "106/106 [==============================] - 6s 55ms/step - loss: 0.6473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKkD5M6eoSiN"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIdQ8c8NvMzV"
      },
      "source": [
        "The simplest way to generate text with this model is to run it in a loop, and keep track of the model's internal state as you execute it.\n",
        "\n",
        "![To generate text the model's output is fed back to the input](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/text_generation_sampling.png?raw=1)\n",
        "\n",
        "Each time you call the model you pass in some text and an internal state. The model returns a prediction for the next character and its new state. Pass the prediction and state back in to continue generating text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjGz1tDkzf-u"
      },
      "source": [
        "The following makes a single step prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSBU1tHmlUSs"
      },
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['', '[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqMOuDutnOxK"
      },
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9yDoa0G3IgQ"
      },
      "source": [
        "Run it in a loop to generate some text. Looking at the generated text, you'll see the model knows when to capitalize, make paragraphs and imitates a Shakespeare-like writing vocabulary. With the small number of training epochs, it has not yet learned to form coherent sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST7PSyk9t1mT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e5f3a9c-d198-43df-9bcf-dff88abeaf8a"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ŞAİR:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*400)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ŞAİR:\r\n",
            "Dört kendine oldum bir kilise, bir gün\r\n",
            "Bir gün, bir damar aynı akşamına.\r\n",
            "Kuşlar uçurum, kan?IDIr elbet\r\n",
            "Kesin daha\r\n",
            "KALI OVURUM\r\n",
            "gün sabahlanılmıştır telâşınü alanıyor, tiren olubüslerini\r\n",
            "Yakma çiçeklerin açlığı\r\n",
            "oy farfara farfara\r\n",
            "ateşlerinde parşai\r\n",
            "elimdeki otel bir yere gideri\r\n",
            "dönüyorum yatağım terseteli\r\n",
            "büyük açaklan herkesin\r\n",
            "kutsal kirazlarına, motorlara yüzükleri\r\n",
            "yıllarca soğra geçirmez bir isyandı, can çol uzar, oynanı\r\n",
            "toprak adamları boğazdan gitmenin yoktu\r\n",
            "ziirapı özleyecektir başkadır\r\n",
            "tutmakları tutturmalıydık kalmasından\r\n",
            "sezmektir\r\n",
            "kimbilir bir dateğit doğa'ya götürüyordu\r\n",
            "denizden ona osmanlığında tam da tutan gelir\r\n",
            "yarı gecesi değişerek\r\n",
            "elimde de şimdilik\r\n",
            "şarkılar söylemez\r\n",
            "nerden baksa/\r\n",
            " ama belleğinde herhangi bir duvar\r\n",
            "ben utançına sinmişliğin vazgeçemlerinin aldı belir\r\n",
            "kara gecen ne kadar küçük\r\n",
            "ortalık gemileri sanı olduk çeşti duvarların\r\n",
            "bir çelişin eli yola çıkınır olduğu yerde\r\n",
            "kim buldu ki bemaz elbit hiç öfte iyidir\r\n",
            "kaldırımızı kazdır insan \n",
            "\n",
            "________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
            "\n",
            "Run time: 2.643146276473999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM2Uma_-yVIq"
      },
      "source": [
        "The easiest thing you can do to improve the results is to train it for longer (try `EPOCHS = 30`).\n",
        "\n",
        "You can also experiment with a different start string, try adding another RNN layer to improve the model's accuracy, or adjust the temperature parameter to generate more or less random predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OfbI4aULmuj"
      },
      "source": [
        "If you want the model to generate text *faster* the easiest thing you can do is batch the text generation. In the example below the model generates 5 outputs in about the same time it took to generate 1 above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkLu7Y8UCMT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b5c49a-7ba8-480a-c3fd-aa54475f192f"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['sair:', 'sair:', 'sair:', 'sair:', 'sair:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\r\\nuykusuzluk ve m\\xc3\\xbckezvr\\xc5\\x9fu vazdim\\r\\nkadehimi k\\xc4\\xb1r\\xc4\\xb1yorlar\\r\\nhasil kalanyad\\xc4\\xb1r.\\r\\nKimi adlar de\\xc4\\x9fildi onlardan\\r\\nMahzun bir h\\xc3\\xbcz\\xc3\\xbcn verir.\\r\\nSapsar\\xc4\\xb1 s\\xc3\\xbccahlardad\\xc4\\xb1r.\\r\\nSOKA\\xc5\\x9e SOLDAYA, BUYUKLAR DURDAR\\r\\nBana b\\xc3\\xb6lerler bir insan geri G\\xc3\\xb6rd\\xc3\\xbc\\xc4\\x9f\\xc3\\xbcm sevgilim\\r\\nbu i\\xc5\\x9fimizi besleyince ans\\xc4\\xb1z\\xc4\\xb1n k\\xc3\\xb6t\\xc3\\xbcl\\xc3\\xbcklerini\\r\\ns\\xc3\\xb6yle bizi k\\xc3\\xb6t\\xc3\\xbcnde biliyorsun\\r\\n-Garson rak\\xc4\\xb1 benzeyebilir.\\r\\nHer \\xc5\\x9fey i\\xc5\\x9fte b\\xc3\\xb6yle oldu, \\xc3\\xb6l\\xc3\\xbcre yakt\\xc4\\xb1m.\\r\\nOysa Kelemes kalans\\xc4\\xb1n\\xc4\\xb1z.\\r\\nBir ba\\xc5\\x9fka hi\\xc3\\xa7 olan\\xc4\\xb1n en g\\xc3\\xbczel sesleri.\\r\\nKINA TU\\xc5\\x9e'n'n bir g\\xc3\\xbcn sabah vakti bitirdim.\\r\\nYERMEL\\xc4\\xb0M\\r\\nS\\xc3\\xb6ylendimiziyor,, ey s\\xc3\\xb6z\\xc3\\xbc, bir g\\xc3\\xb6n b\\xc3\\xbcy\\xc3\\xbck ve kanlar\\r\\nKalk\\xc4\\xb1l\\xc4\\xb1lm\\xc4\\xb1\\xc5\\x9f bir yalan h\\xc3\\xbcz\\xc3\\xbcnleneyi,\\r\\nuzak uzak uykusuzlar, sedef kanak\\xc4\\xb1n g\\xc3\\xb6\\xc4\\x9fs\\xc3\\xbcnde.\\r\\nD\\xc3\\xbcnyaya u\\xc3\\xa7guma, dursun,\\r\\nBen \\xc5\\x9fimdiden yapran\\xc4\\xb1n..\\r\\nBa\\xc5\\x9f\\xc4\\xb1nda ne var ne ak\\xc5\\x9fam\\r\\nTayfan\\xc4\\xb1n bir d\\xc3\\xbcnya ge\\xc3\\xa7melisin bir\\xc5\\x9firiniz\\r\\n(ATbez\\r\\nal\\xc4\\xb1rs\\xc4\\xb1n kimbilir ki bozar\\xc4\\xb1yor\\r\\n-b\\xc3\\xbct\\xc3\\xbcn a\\xc4\\x9fa\\xc3\\xa7lar birer mavi\\r\\nher \\xc5\\x9fey harbenin olan\\xc4\\xb1n a\\xc4\\x9fz\\xc4\\xb1ndan\\r\\n\\xc3\\xb6yle tastan yapraklar\\xc4\\xb1 sararan\\r\\nile ta\\xc5\\x9f\\xc4\\xb1kt\\xc4\\xb1r \\xc3\\xa7\\xc3\\xbcnk\\xc3\\xbc utanm\\xc4\\xb1\\xc5\\x9f\\r\\nda\\xc4\\x9f\\xc4\\xb1t\\xc4\\xb1rlar\\r\\nboy nibetle kendi askerleriyle\\r\\nyazd\\xc4\\xb1n\\xc4\\xb1z, nerden \\xc3\\xb6peciksiz sahitsizlik\\r\\nben bura\"\n",
            " b'ROMEO:\\r\\n\\xc3\\xb6l\\xc3\\xbcm \\r\\n43\\r\\nh\\xc3\\xbct\\xc3\\xbcn mevisi, ba\\xc5\\x9fka ne kele,\\r\\ney yeniden g\\xc3\\xbcne\\xc5\\x9flesiydi,\\r\\ngitti dersindir\\r\\nbenim \\xc3\\xbc\\xc3\\xa7genleri ne \\xc3\\xbczeyin en g\\xc3\\xbczel\\r\\ninceliz m\\xc3\\xbclher \\xc3\\xa7\\xc3\\xb6rkmeyince bir da\\xc4\\x9f ba\\xc5\\x9f\\xc4\\xb1nda\\r\\nbo\\xc5\\x9f derinli\\xc4\\x9fini b\\xc3\\xb6t\\xc3\\xbcrs\\xc3\\xbczl\\xc3\\xbc\\xc4\\x9f\\xc3\\xbcn\\xc3\\xbc\\r\\n\"o\\xc4\\x9ful \\xc5\\x9fehri\\r\\nne bundurum bitirmi\\xc5\\x9f kitap\\r\\n\\xc3\\xa7\\xc4\\xb1lg\\xc4\\xb1n bir g\\xc3\\xbcl yer al\\xc4\\xb1yor\\r\\nnesi ba\\xc5\\x9flad\\xc4\\xb1 afferi\\r\\nal\\xc4\\xb1p verilse,\\r\\ntiren dolu kad\\xc4\\xb1nlar\\xc4\\xb1 \\xc3\\xbc\\xc3\\xa7 yang\\xc4\\xb1\\xc3\\xa7 kesiyorsun\\r\\nBir par\\xc3\\xa7a ekmek sil\\xc3\\xa2h, sayd\\xc4\\xb1klar\\xc4\\xb1 var ama, onlar\\xc4\\xb1n g\\xc3\\xb6rd\\xc3\\xbc\\xc4\\x9f\\xc3\\xbc.\\r\\nEn faze, havalar b\\xc3\\xbcy\\xc3\\xbck yapra\\xc4\\x9f\\xc4\\xb1 \\xc3\\xb6\\xc4\\x9f\\xc3\\xbctleri ald\\xc4\\xb1lar - devrim ge\\xc3\\xa7e olarak\\r\\n2.. viraj\\xc4\\xb1 d\\xc3\\xb6nd\\xc3\\xbc.\\r\\nBir nas\\xc4\\xb1r solu\\xc4\\x9fu be\\xc5\\x9f ge\\xc3\\xa7erdidir, bir duman, bir a\\xc4\\x9flad\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1\\r\\n\\xc4\\xb0ki kendine yeten diyorum, b\\xc3\\xb6yle olmal\\xc4\\xb1yd\\xc4\\xb1..\\r\\nBu k\\xc3\\xb6t\\xc3\\xbc deniz Eskir oldu, ba\\xc5\\x9f\\xc4\\xb1ndan.\\r\\nBulutlar fi\\xc3\\xa7alara.\\r\\nG\\xc3\\xbczelsinez.\\r\\nA\\xc5\\x9fk\\xc4\\xb1 b\\xc3\\xbct\\xc3\\xbcn b\\xc3\\xbcy\\xc3\\xbck k\\xc3\\xb6rler de\\xc4\\x9ferlere Bakt\\xc4\\xb1m.\\r\\nG\\xc3\\xbcnd\\xc3\\xbczleri g\\xc3\\xbcndan\\r\\nBir yere gelse. Belki uyuyan, \\xc3\\xa7a\\xc4\\x9f\\xc4\\xb1ran...\\r\\nBir \\xc5\\x9feyler yoktu. O ademdi,\\r\\nBir ordu var89si bir\\r\\naradan orman\\xc4\\xb1, sular b\\xc3\\xbct\\xc3\\xbcn ve u\\xc3\\xa7kulu alevleri\\r\\ng\\xc3\\xbcsterine k\\xc3\\xbcrek\\xc3\\xa7eler, duraklardas\\xc4\\xb1n yabanc\\xc4\\xb1 gider,\\r\\nOysa ka\\xc5\\x9flar\\xc4\\xb1n\\xc4\\xb1 duyar\\xc4\\xb1kt\\xc4\\xb1r, almanya\\'da.\\r\\n\\xc5\\x9e KARDI ID.*\\r\\nBen bir g\\xc3\\xbcn bir u\\xc3\\xa7urums'\n",
            " b'ROMEO:\\r\\nbiz gelen adamlar\\xc4\\xb1n\\r\\nk\\xc4\\xb1vanlar\\xc4\\xb1n en g\\xc3\\xbczel ar\\xc4\\xb1yla ve bir saat\\r\\n renca denizin alacakirin ak\\r\\ng\\xc3\\xb6ky\\xc3\\xbcz\\xc3\\xbc bir baharda bakars\\xc4\\xb1n\\xc4\\xb1z. Ka\\xc3\\xa7 g\\xc3\\xbcnd\\xc3\\xbcrd\\xc3\\xbc, evler, d\\xc3\\xbc\\xc5\\x9f\\xc3\\xbcr\\xc3\\xbcrler\\r\\nve kan dektar\\xc4\\xb1 \\xc3\\xa7\\xc4\\xb1k\\xc4\\xb1mlardan, sezdiler,\\r\\ns\\xc3\\xb6ylensin \\xc3\\xb6yle \\xc3\\xa7ocuklara\\r\\nvard\\xc4\\xb1 kurtulmak.\\r\\nKurtulmu\\xc5\\x9f olanlardan\\r\\nAl\\xc4\\xb1p yaracak olsak her \\xc5\\x9fey, herkese ben.\\r\\nBir ordu vard\\xc4\\xb1. Lok\\xc3\\xbcyordu\\r\\nbir sokakta ya\\xc4\\x9far, d\\xc3\\xb6rt bir dile ben var\\xc4\\xb1m\\r\\n\\xc3\\xbcrpertil ba\\xc5\\x9f\\xc4\\xb1 ve a\\xc4\\x9flaman\\xc4\\xb1n g\\xc3\\xb6rseniz kesecesi kesmi\\xc5\\x9f, neler olurlar Kin-i\\r\\n(\\xc5\\x9fe\\xc5\\x9f yaln\\xc4\\xb1z kalmaya haz\\xc4\\xb1r\\xc4\\xb1yor geni\\xc5\\x9ftir tutan and\\xc4\\xb1rd\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1\\r\\nsran f\\xc4\\xb1rt\\xc4\\xb1na bula\\xc5\\x9fmad\\xc4\\xb1k\\r\\nm\\xc4\\xb1s\\xc4\\xb1r pen\\xc3\\xa7elerden d\\xc3\\xb6nercin y\\xc3\\xb6ngelirim sakallar\\xc4\\xb1\\r\\n\\xc3\\xa7evremiz \\xc3\\xa7ocuklar\\xc4\\xb1n neden a\\xc4\\x9flar,\\r\\ni\\xc3\\xa7inde bir par\\xc3\\xa7a kitab\\xc4\\xb1\\r\\nkalkb\\xc4\\xb1lanmak yava\\xc5\\x9f katlan\\xc4\\xb1lmam\\xc4\\xb1\\xc5\\x9f bir hastanelere ve\\r\\nkendi \\xc3\\xb6b\\xc3\\xbcr\\xc3\\xbcnden birer.\\r\\n\\xc4\\xb0\\xc5\\x9fe evi\\xc3\\xa7lerinde, beslersun sena\\r\\nY\\xc4\\xb1kan\\xc4\\xb1r maranl\\xc4\\xb1k,\\r\\nKiminin bir anam\\xc4\\xb1 az\\xc4\\xb1rd\\xc4\\xb1m. \\xc3\\x96yle kald\\xc4\\xb1 ays\\xc4\\xb1ld\\xc4\\xb1n,\\r\\nZaten bizi herinle neden ka\\xc3\\xa7malar, art\\xc4\\xb1k k\\xc3\\xbc\\xc3\\xa7\\xc3\\xbcklerini Almaya\\r\\nO neler olup olmaz, istanbul\\r\\nElimde k\\xc4\\xb1zl\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1n durursa onu g\\xc3\\xb6r\\xc3\\xbcrd\\xc3\\xbck\\r\\nAma o eve bakt\\xc4\\xb1m, seni g\\xc3\\xb6rmeyebilen.\\r\\nKalabal\\xc4\\xb1k\\r\\nKald\\xc4\\xb1'\n",
            " b'ROMEO:\\r\\nL\\xc3\\x9cGTARI SAK\\r\\nGel ba\\xc5\\x9flar gizliden\\r\\nBir g\\xc3\\xbcn, bir yepmeyi ve mavi d\\xc3\\xbc\\xc5\\x9fm\\xc3\\xbc\\xc5\\x9f\\r\\nKi ar\\xc4\\xb1n\\xc4\\xb1n tad\\xc4\\xb1ns\\xc4\\xb1zl\\xc4\\xb1\\xc4\\x9fsan, g\\xc3\\xbcne\\xc5\\x9ften \\xc4\\xb1\\xc5\\x9f\\xc4\\xb1k\\r\\nBir \\xc3\\xbclken bir \\xc3\\xa7ocuk, bir k\\xc4\\xb1z yata\\xc4\\x9f\\xc4\\xb1nda\\r\\nBir g\\xc3\\xbcn, bir par\\xc3\\xa7a en g\\xc3\\xb6ze sakaz\\r\\nYo\\xc4\\x9fun duygular\\xc4\\xb1n\\xc4\\xb1n g\\xc3\\xbczelli\\xc4\\x9fi d\\xc3\\xbcmd\\xc3\\xbcrd\\xc3\\xbc. Y\\xc4\\xb1ld\\xc4\\xb1zlar art\\xc4\\xb1yor biliyorum. Onlar o kadard\\xc4\\xb1r.\\r\\nAl\\xc4\\xb1\\'kinin \\xc3\\xb6nce 1820 de\\xc4\\x9fil.\\r\\nNe \\xc3\\xb6zet be\\xc5\\x9fti, g\\xc3\\xb6z\\xc3\\xbcn\\xc3\\xbcze, sabahlar\\xc4\\xb1. Lizlere\\r\\nBana g\\xc3\\xb6r\\xc3\\xbc\\xc5\\x9ft\\xc3\\xbc gendiM..\\r\\nDolanam saklamasak.\\r\\nYALAM\\r\\nS\\xc3\\x96ZLER\\xc4\\xb0\\r\\n\"Kan\\xc4\\xb1m kahvede, bir \\xc3\\xb6zlemle mavistan\\r\\nKutrak davundaki \\xc3\\xa7\\xc3\\xb6l ylendeki g\\xc3\\xbcveyi diliyorum\\r\\nBir bebekten hepinizin ba\\xc5\\x9flad\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1\\r\\nKat\\xc4\\xb1l b\\xc3\\xbct\\xc3\\xbcn tazeleri g\\xc3\\xbcl at\\xc4\\xb1na varSa yerde mi\\r\\n\\xc4\\xb0SL DENS\\xc4\\xb0L\\xc4\\xb0R\\r\\n\\xc4\\xb0kimiz ba\\xc5\\x9f\\xc4\\xb1mda bu benden nemet bu ard\\xc4\\xb1na kadar\\r\\nSonra belle\\xc4\\x9fimde ez d\\xc3\\xbc\\xc4\\x9fmesini d\\xc3\\xb6n\\xc3\\xbcn\\xc3\\xbcrden.\\r\\nKANADA K\\xc4\\xb0TMEMEK\\r\\nDursuzluk an\\xc4\\xb1lmam\\xc4\\xb1z seni, ay\\xc4\\xb1\\xc5\\x9f\\xc4\\xb1\\xc4\\x9fm \\xc3\\xbcst\\xc3\\xbcne ba\\xc5\\x9fkas\\xc4\\xb1n\\r\\nBu K\\xc4\\xb1rm\\xc4\\xb1z\\xc4\\xb1 bir bak\\xc4\\xb1\\xc5\\x9fta tan\\xc4\\xb1d\\xc4\\xb1 \\xc4\\xb0stanbul g\\xc3\\xbcc\\xc3\\xbcm yetti\\r\\nDa\\xc4\\x9frand\\xc4\\xb1 g\\xc3\\xb6rd\\xc3\\xbcm vayolsa yitirdim yorgan\\xc4\\xb1\\r\\nel\\'in ta\\xc5\\x9fta kanl\\xc4\\xb1 e\\xc4\\x9flar\\xc4\\xb1n\\xc4\\xb1n sonsuz g\\xc3\\xbclbeyaz\\r\\nkadehlerini besleyen\\r\\ngelir gider o kadar kedirerek\\r\\nbiz s\\xc4\\xb1ras\\xc4\\xb1z buradan noktalar gibi \\xc3\\xa7\\xc4\\xb1nlad\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1 \\xc3\\xbcrk\\xc3\\xbct\\xc3\\xbcbi\\r\\ng\\xc3\\xbcld\\xc3\\xbcr'\n",
            " b'ROMEO:\\r\\n\"ben b\\xc3\\xbct\\xc3\\xbcn h\\xc3\\xbczn\\xc3\\xbcm b\\xc3\\xbct\\xc3\\xbcn ayg\\xc4\\xb1rbet ve \\xc3\\xb6l\\xc3\\xbcm\\r\\nbiten bir b\\xc3\\xbcy\\xc3\\xbck tahutluyor\\r\\ntutanaklardan uyanak tekin li\\xc5\\x9f\\xc3\\xa2\\r\\nelleri h\\xc3\\xbcz\\xc3\\xbcn\\'le bolusu\\r\\nbir beyaz yeni diriyi arad\\xc4\\xb1k\\xc3\\xa7a\\r\\naslan ho\\xc5\\x9fuma gittiniz mi?\\r\\nBen gitmi\\xc5\\x9ftir ay \\xc4\\xb1\\xc5\\x9f\\xc4\\xb1kl\\xc4\\xb1l\\xc4\\xb1kt\\xc4\\xb1r\\r\\nK\\xc4\\xb1rlar\\xc4\\xb1n y\\xc3\\xbcz\\xc3\\xbc ak\\xc4\\xb1yordu Azard\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1m\\xc4\\xb1z g\\xc3\\xbcne\\xc5\\x9ften dikili k\\xc4\\xb1y\\xc4\\xb1sanda\\r\\nSabahlara kadar kur\\xc5\\x9funa diziyorlar\\r\\nB\\xc3\\xbct\\xc3\\xbcn kara par\\xc3\\xa7alar\\xc4\\xb1nda\\r\\nAfrika dahil\\r\\nSulyata ya\\xc5\\x9fmayacak \\xc5\\x9fu korkuya sokaklar olmal\\xc4\\xb1d\\xc4\\xb1r\\r\\nBen seni utan\\xc4\\xb1r bir ki\\xc5\\x9fiye ay\\xc4\\xb1rd\\xc4\\xb1m herkes\\r\\nBen solu\\xc4\\x9fu Meryem\\xe2\\x80\\x99in \\xc3\\xbcst\\xc3\\xbcm\\xc3\\xbczden geceye kar\\xc4\\xb1\\xc5\\x9f\\xc4\\xb1r\\r\\nsuya d\\xc3\\xb6n\\xc3\\xbcm\\xc3\\xbc birden g\\xc3\\xb6nl\\xc3\\xbcnde kald\\xc4\\xb1n\\r\\nsu yap\\xc4\\xb1lan yazd\\xc4\\xb1\\xc4\\x9f\\xc4\\xb1 g\\xc3\\xbcn Muthul kanatlar\\xc4\\xb1nda\\r\\nbulunurlarken d\\xc3\\xbc\\xc5\\x9f\\xc3\\xbcnse de sonu\\xc3\\xa7suz \\xc3\\xa7\\xc4\\xb1kan bir duvar\\r\\nBen de \\xc3\\xa7\\xc4\\xb1pla\\xc4\\x9f\\xc4\\xb1m ama esmi\\r\\nKimbilir kimin kar\\xc4\\xb1s\\xc4\\xb1\\r\\nAda \\xc4\\xb1ndaz a\\xc5\\x9fa\\xc4\\x9f\\xc4\\xb1 \\xc3\\xb6n\\xc3\\xbcn\\xc3\\xbcze geldi\\xc4\\x9fimiz,\\r\\nSesi yoksa, uzan\\xc4\\xb1r mesel\\xc3\\xa2:\\r\\nK\\xc4\\xb1z\\xc4\\xb1m k\\xc4\\xb1v\\xc4\\xb1lc\\xc4\\xb1mlardan.\\r\\nHi\\xc3\\xa7 uyu hem biraz daha bak\\xc4\\xb1n\\r\\nTurgan san\\xc4\\xb1l\\xc4\\xb1r ki bumdan bu\\r\\nSonbahar\\xc4\\xb1 beklemeler;\\r\\n\\xc3\\x87\\xc4\\xb1k\\xc4\\xb1nt\\xc4\\xb1lar kolar, s\\xc3\\xbcslenmi\\xc5\\x9f bahar\\xc4\\xb1.\\r\\nD\\xc3\\xbcnyada\\r\\nD\\xc3\\xbcnyaya geldim gidiyorum.\\r\\nBu k\\xc3\\xb6y, nas\\xc4\\xb1l oluyor. Sona\\xc3\\xa7 etirdi batenlere aslanan. koparken\\r\\nbardan ate\\xc5\\x9f bir\\xc5\\x9f'], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.74436616897583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlUQzwu6EXam"
      },
      "source": [
        "## Export the generator\n",
        "\n",
        "This single-step model can easily be [saved and restored](https://www.tensorflow.org/guide/saved_model), allowing you to use it anywhere a `tf.saved_model` is accepted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Grk32H_CzsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1aeda7-615b-413d-c1e7-6dd2ba39e0c5"
      },
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f92547a6810>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
            "\n",
            "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Z9bb_wX6Uuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7185f64d-b028-444d-f978-3d176f2138f6"
      },
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ŞAİR:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ŞAİR:\r\n",
            "Sönük bir salınan\r\n",
            "Gül kurusu casde...\r\n",
            "Karanlıkta öğle yalnızlığım bir adam için yoksa, bir fican\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4QwTjAM6A2O"
      },
      "source": [
        "## Gelişmiş: Özelleştirilmiş Eğitim\n",
        "\n",
        "Yukarıdaki eğitim prosedürü basittir, ancak size fazla kontrol sağlamaz.\n",
        "Kötü tahminlerin modele geri beslenmesini önleyen öğretmen zorlamasını kullanır, böylece model asla hatalardan kurtulmayı öğrenmez.\n",
        "\n",
        "Artık modeli manuel olarak nasıl çalıştıracağınızı gördüğünüze göre, eğitim döngüsünü uygulayacaksınız. Bu, örneğin, modelin açık döngü çıktısını dengelemeye yardımcı olmak için _müfredat öğrenimi_ uygulamak istiyorsanız bir başlangıç noktası sağlar.\n",
        "\n",
        "Özel bir eğitim döngüsünün en önemli kısmı, tren adımı işlevidir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0pZ101hjwW0"
      },
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKyWiZ_Lj7w5"
      },
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U817KUm7knlm"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o694aoBPnEi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87e0c7c-0efb-4397-a0bd-396cf08c59e2"
      },
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 8s 55ms/step - loss: 2.9342\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9260aaf690>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8nAtKHVoInR"
      },
      "source": [
        "Or if you need more control, you can write your own complete custom training loop:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4tSNwymzf-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edfd495e-4af0-42a8-c73f-040cfb42b792"
      },
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.2903\n",
            "Epoch 1 Batch 50 Loss 2.1710\n",
            "Epoch 1 Batch 100 Loss 2.1250\n",
            "\n",
            "Epoch 1 Loss: 2.1680\n",
            "Time taken for 1 epoch 6.85 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 2.0554\n",
            "Epoch 2 Batch 50 Loss 2.0279\n",
            "Epoch 2 Batch 100 Loss 1.9413\n",
            "\n",
            "Epoch 2 Loss: 2.0219\n",
            "Time taken for 1 epoch 10.24 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.9597\n",
            "Epoch 3 Batch 50 Loss 1.8814\n",
            "Epoch 3 Batch 100 Loss 1.9033\n",
            "\n",
            "Epoch 3 Loss: 1.9042\n",
            "Time taken for 1 epoch 6.39 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.8348\n",
            "Epoch 4 Batch 50 Loss 1.8214\n",
            "Epoch 4 Batch 100 Loss 1.8050\n",
            "\n",
            "Epoch 4 Loss: 1.7975\n",
            "Time taken for 1 epoch 6.33 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.7254\n",
            "Epoch 5 Batch 50 Loss 1.7436\n",
            "Epoch 5 Batch 100 Loss 1.6629\n",
            "\n",
            "Epoch 5 Loss: 1.7048\n",
            "Time taken for 1 epoch 6.42 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.6930\n",
            "Epoch 6 Batch 50 Loss 1.6940\n",
            "Epoch 6 Batch 100 Loss 1.6040\n",
            "\n",
            "Epoch 6 Loss: 1.6258\n",
            "Time taken for 1 epoch 6.32 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.5881\n",
            "Epoch 7 Batch 50 Loss 1.5058\n",
            "Epoch 7 Batch 100 Loss 1.6233\n",
            "\n",
            "Epoch 7 Loss: 1.5569\n",
            "Time taken for 1 epoch 6.29 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.4931\n",
            "Epoch 8 Batch 50 Loss 1.5376\n",
            "Epoch 8 Batch 100 Loss 1.5139\n",
            "\n",
            "Epoch 8 Loss: 1.4901\n",
            "Time taken for 1 epoch 6.27 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.4227\n",
            "Epoch 9 Batch 50 Loss 1.4512\n",
            "Epoch 9 Batch 100 Loss 1.4068\n",
            "\n",
            "Epoch 9 Loss: 1.4258\n",
            "Time taken for 1 epoch 6.25 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.2991\n",
            "Epoch 10 Batch 50 Loss 1.4271\n",
            "Epoch 10 Batch 100 Loss 1.3719\n",
            "\n",
            "Epoch 10 Loss: 1.3594\n",
            "Time taken for 1 epoch 6.34 sec\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85ky_sSbMSJi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a5063f-fbac-420a-bb94-ca97fa620251"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "#next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n\r\n",
            "Sevdalı yaşanırlardı gidip gelmelerde. Ardına kadar\r\n",
            "Turnam ben söndüğünü görmemiş.\r\n",
            "Fakirliğiye, bir nice seni,\r\n",
            "halde bile beyazlarında kavga çok geldi\r\n",
            "-suy hartmiz masa, dal bir şeyler haçıldı, bilmedim yazdıklarım:\r\n",
            "bütün çiçeklerle tutkusuzlukla değişir\r\n",
            "harcunç çekirse de evrensel yetişiriz,\r\n",
            "sonsuz girişim kendi derdi ye yakış\r\n",
            "ya bir bu bu akin\r\n",
            "neya hambettiğimiz\r\n",
            "sen göğsünde bunların üstünden\r\n",
            "öldürül esirgiçemizleri\r\n",
            "rüzgârın eskidirlerin.\r\n",
            "zaten yememişlere alışkın öbürleriyle sulara göke lina denge\r\n",
            "Korkunun ilk yapılır kralin yolundaydı\r\n",
            "Babamın ağladığını duyuyorlar, bildikleri, getirdim.\r\n",
            "SESSİN YER BEYLEDİ\r\n",
            "Oysa k o k de ki, Varda durdu Herkes\r\n",
            "Yürek geceye darmadağın\r\n",
            "Vapurlarım dökünün o dilin kullanından\r\n",
            "Bir o redi benden nedir.\r\n",
            "Gözlerinde yazması...\r\n",
            "Siysiler, bel, gemiciler,\r\n",
            "Fasmanını kovalamaktı.\r\n",
            "Kuru bir sözüm, kuruyorum canıma\r\n",
            "IIÇtılar birden başladı sarmıyordum\r\n",
            "gülluğuma içinde herhalde ve gökten korkar'sa\r\n",
            "ben alınız al müzüm ki unutulmaz bir deniz  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.0542635917663574\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOeIhwCVE6Bv",
        "outputId": "28331838-b9c0-48bc-c905-c0e81df41b72"
      },
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['Şair:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Şair:\r\n",
            "ÇaĞRI GÜLÜN BİRİ GELİŞ\r\n",
            "Dursuz düzeninde çanta kaybolun\r\n",
            "Güley gerekesi...\r\n",
            "Bu evlerini akıyordu. Gözlerinde\r\n",
            "Biz bu harladığımı gördük. Kim tek tek bitti\r\n",
            "Hey gözüne katmış bir\r\n",
            "lerzet her aklımda:\r\n",
            "o kedi gözleriyle yedilenle kederse, bir dağın yağmuru yanılmadın, telcik olur.\r\n",
            "Kimbilir kaç kere öpsem ikinin hatırı için\r\n",
            "Akşam akşam yanmıştım, o levlik.\r\n",
            "Babam, Yani Sül burada kalsın..\r\n",
            "Bekleşmeyen düzdanın yılmanın yeniden başla hen\r\n",
            "bir kaptan ki artık elleridir.\r\n",
            "Göl yaban, tay büyütürsünü, bir kadınla bir şeyler yorgun gemilere, hey gidi.\r\n",
            "Gelir durmuş; Paslatacaksın. Dünoyla beni yeni bir adam, köyünden\r\n",
            "En uzun, bir karıştı, jamparaları durgunluktur\r\n",
            "Bir geceyi bir kadından korkur yolcularıydı..\r\n",
            "Bir durup bütün bunlar bütün yalnızlığın adını...\r\n",
            "HIZLAN DÖMÜDA\r\n",
            "Şimdi bir güvercinin\r\n",
            "Şu dönleri görmedim, Sarhoşuo\r\n",
            "Kent ey sevişin, yoktursa, daha da esmer içindeydi.\r\n",
            "Basınmalar güzelde, bundan,\r\n",
            "Bana Böneş kesip udanıyorum ki\r\n",
            "Beni şaşırdım durdum.\r\n",
            "Kendi divalarla\r\n",
            "O güneş vur \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.0720365047454834\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}